\paragraph{Invariant learning.}
%
\citet{SohDunAngGuetal20} and \citet{creager2021environment} both consider a similar problem, where
the data also exhibits a two-level hierarchy formed by classes and subgroups.
%
In contrast to our work, however, there is no additional bias in the data; while they may be
unobserved, the labelled data is assumed to have complete class-conditional support over the
subgroups.
%
As such, these methods are not directly applicable to the particular form of the problem we
consider.
%
Like us, \citet{SohDunAngGuetal20} uses semi-supervised clustering to uncover the hidden subgroups,
however their particular clustering method requires access to the class labels not afforded by the
deployment set, as does the training of the robust classifier.

\paragraph{Unsupervised domain adaptation.}
%
In \acf{UDA}, there are typically one or more source domains, for which training labels are
available, and one or more unlabelled target domains to which we hope to generalise the classifier.
%
A popular approach for solving this problem is to learn a representation that is invariant to the
domain using adversarial networks \citep{ganin2016domain} or non-parametric discrepancy measures
such as \ac{MMD} \citep{gretton2012kernel}.
%

There are two ways in which one can compare UDA to our setting: 1) by treating the subgroups as
domains; and 2) by treating the training and the deployment set as ``source'' and ``target''
domains, respectively.
%
The first comparison is exploited in algorithm fairness, yet does not carry over to our setting in
which the labelled data contains \emph{incomplete} domains. 
%
When all sources from a given domain are missing then there are no domains to be matched, and even
when this is not the case, matching will result in misalignment due to differences in
class-conditional support.
%
The second comparison is more germane but ignores an important aspect of our problem: the presence
of \acp{SC}.
%

Similar to us, \citet{tong2022adversarial} utilise adversarial methods to align the support of two
distributions in a semi-supervised regime -- specifically, they propose to use symmetric support
difference as a divergence measure which they realise using a discriminator. 
%
However, their method focuses on label-shift in the \ac{UDA} setting and does not consider the
hierarchical structure that exists within the source (training) and target (deployment) domains,
and as such they do not consider the notion of ``missing sources'' that can arise due to said
structure -- the characterisation of this problem is one of the two main contributions of this work
(the other being our proposed solution). 
%
Furthermore, the discriminator used therein is applied instance-wise; we show in
\ref{sec:sm-ablations} that allowing the discriminator to model inter-sample relationships has
tangible addition benefits when performing support-matching.

\paragraph{Multiple instance learning}
%
Multiple instance learning \citep{maron1998framework} is a form of weakly-supervised learning in
which samples are not labelled individually part as part of a set or \emph{bag} of samples.
%
In the simplest (binary) case, a bag is labelled as positive if there is a single instance of a
positive class contained within it, and negative otherwise.
%
In our case, we can view the missing sources as constituting the positive classes, which leads to
all bags (a term we will use throughout the paper distinctly from ``batches'') from the deployment
set being labelled as positive, and all bags from the training set being labelled as negative.
%
Given this labelling scheme, we make use of an adversarial set-classifier to align the supports of
the training and deployment sets in the representation space of an encoder network.
%

\paragraph{Positive unlabelled learning}
%
Learning from positive and unlabelled data, or \emph{PU learning}, refers to the
binary-classification setup in which the labelled training data consists of only positive samples
while additional unlabelled data is assumed to contain both positive and negative samples
\citep{liu2002partially, liu2003building, bekker2020learning}. 
%
This is analogous to our problem setting if we consider the positive class to be all samples
sources represented in the training set, collectively, while the missing sources collectively make
up the negative class. 
%
However, the goal here is not merely to learn the classification boundary between the present and
missing sources but to learn to classify the target class of a given sample independently of its
subgroup.
%
This is equivalent to requiring that a classifier trained to distinguish between positive and
negative classes, according to the aforementioned PU learning setup, from the pre-logits layer of
our desired classifier be maximally entropic -- we propose to use adversarial learning to achieve
this.
%
