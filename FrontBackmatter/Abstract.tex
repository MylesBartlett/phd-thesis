%*******************************************************
% Abstract
%*******************************************************
%\renewcommand{\abstractname}{Abstract}
\pdfbookmark[1]{Abstract}{Abstract}
% \addcontentsline{toc}{chapter}{\tocEntry{Abstract}}
\begingroup
\let\clearpage\relax
\let\cleardoublepage\relax
\let\cleardoublepage\relax

\chapter*{Abstract}
%
% This thesis contends with problems of \emph{distribution shift} under various guises and proposes
% several mettods for mitigating their impact on deep learning (DL) models by capitalising on
% additional unlabelled (or partially-labelled) data. 
%
Over but the last decade, deep learning has paved the way for machine-learning systems achieving
unprecedented levels of performance on myriad real-world tasks by learning complex decision rules
directly from large quantities of data.
% prediction \citep{jumper2021highly}, algorithm discovery \citep{fawzi2022discovering}, and
% language comprehension \citep{brown2020language}. % However, DL models can also be brittle owing
% to their fundamentally statistical -- rather than causal -- nature, something that has led to
% spectacular failures in safety-critical and ethically-sensitive applications.
%
However, the data-driven, and fundamentally statistical -- rather than causal -- nature of these
systems is a double-edged sword that has led to catastrophic, difficult-to-diagnose, failures in
various safety-critical and ethically-sensitive applications.
%
% Crucially, since it takes distributional-shift to expose this brittleness, such problems are
% difficult to diagnose in development; we consider problems characterised by such, wherein
% data-derived biases interplay with underspecification and distributional mismatch.
%
Indeed, worryingly often they learn to exploit \emph{shortcuts} that are extraneous \wrt{} the
underlying task.
%
% \cite{zech2018variable}, for instance, famously demonstrated that one can train a model for
% pneumonia diagnosis achieving near-perfect accuracy solely based on the site-specific tags and
% the associated prevalence rates -- such a model is demonstrably useless (which is to say,
% dangerous) in practice despite its well-satisfying the training objective.
%
This is said to be a problem of \emph{shortcut-learning}; the first two papers constituting this
thesis tackle different manifestations of such with appropriately different solutions, both
predicated on leveraging additional data to obviate biases immanent in the training data.
%, consistent with the overarching theme of semi-supervision.
%
In the first, we consider a setup in which sampling bias induces a one-to-one correspondence
between subgroup and target; since learning from the training data alone is ill-posed, we propose
a two-stage, interpretable framework exploiting the unique properties of invertible models, founded
on the assumption that more-diverse unlabelled data is often readily obtainable, e.g. from
censuses.
%
In the second, we relax the aforementioned problem such that subgroup-target combinations are
missing in an asymmetric fashion, \wrt{} the target, and propose to solve this by matching the
support of the training set with that of an unlabelled dataset representative of the test set. 
%
This is realised through a combination of clustering, adversarial training with a set
discriminator, and a hierarchical-sampling strategy.
%
The third and final paper contends with the broader problem of generalising to data from
\emph{domains} outside the training distribution  and how unlabelled data from extra domains can
effectively further this goal.
%
Here, changes in domain induce natural distribution shifts corresponding, for example, to
variations in lighting, perspective, and environs; to counteract them, we propose a simple,
consistency-regularised approach employing causal matching.
%this can be effective for semi-supervised domain generalisation across a range of tasks and
%modalities.


\endgroup

\vfill
