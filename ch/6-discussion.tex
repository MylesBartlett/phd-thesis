\chapter{Discussion and future work}\label{ch:conclusion}
In this thesis, I have presented three approaches to deal with dataset bias.
The first one deals with a form of label bias and the other two with forms of sampling bias.
However, this by no means covers \emph{all} possible biases,
but it contributes to a growing literature that tries to tackle this problem.
One could ask if there is one method that is able to cover all possible dataset biases,
but I think there is a strong argument to be made that no general method can exist,
because it is, \eg, not possible to describe in general what is spurious information and what is relevant information.

Thus, correcting dataset bias remains a challenging topic
and one that is relevant to today's machine learning applications.
Any cutting-edge \ac{ML} system will have to deal with imperfect data,
especially if the collected data is human-related.
The results of these data imperfections are certainly highly undesirable:
you do not want your photo tagging service to only work for a certain kind of person;
you do not want your speech recognition system to only work for a certain kind of dialect.
If, in these situations, enough representative (but unlabeled) data is available,
then the methods presented here can be used to try and correct the problem.



Nevertheless, the methods presented here \emph{are} relevant to real-world problems.
