% ****************************************************************************** 
\section*{Preamble}
% ****************************************************************************** 
\noindent
%
In this chapter, I aim to provide background on the topics spanned by the works in this thesis,
both individually, and holistically.
%
While I will on occasion point to exemplar methods, generally I will eschew delving deep into
specific methodologies -- of which there are many and many more being proposed by the day -- in
favour of keeping broader perspectives regarding the motivations of, assumptions made by, and
interconnections between, the considered paradigms. 
%
This is to say, this chapter does not aspire to be a comprehensive survey of \ac{DA}, \ac{DG},
\ac{AF}, and the other germane subfields touched on herein; producing such for any one of these
subfields is in itself a considerable undertaking given the breadth and depth the \ac{ML}
literature, the field having grown precipitously over the last decade since the onset of the
deep-learning revolution.
%
The aspirations of this chapter, on the contrary, are much more humble, simply being to provide the
requisite (high-level) background for, and unified and alternative perspectives of, the problems
and methodologies featured in Chapters \ref{ch:nifr}, \ref{ch:supmatch} and \ref{ch:okapi}.
%
Indeed, each of said chapters contain their own background sections drawing direct comparisons to
related work and I wish to avoid repetition in this respect.

The main themes of this thesis -- as just introduced -- are \ac{SemiSL} and \ac{DR}, the latter in
the context of \ac{AF} (Chapters \ref{ch:nifr} and \ref{ch:supmatch}) and \ac{DG} (Chapter
\ref{ch:okapi}), specifically. 
%
I will cover these topics directly, but to properly contextualise and motivate them requires
visiting both foundational and adjacent areas of \ac{ML}.

%
With the above in mind, I begin with discussion of the classical \ac{SL} setup and how standard
\ac{ERM} is ill-suited to long-tailedness and distribution shifts, both pervasive phenomena in
real-world applications. 
%
`Distributions shift' as a term is highly polysemous, meaning very different things, and demanding
commensurately different solutions, depending on the underlying mechanisms and the direction of
causality. 
%
I will give a brief taxonomy of the different kinds of distribution shifts in terms of how the
marginal and conditional distributions are affected, and what may cause them. 

%
\acfp{SC}, or (statistical) shortcuts (I will use the terms interchangeably throughout), give rise
to a particularly aggressive form of distribution shift as a result of features in the training
data being highly (conceivably to the degree of a one-to-one correspondence) correlated with the
target but not in a way that is causally consistent, and thus in a way that should not be expected
to hold consistently at test time. 
%
The idea of \acp{SC} is central to both Chapters \ref{ch:nifr} and \ref{ch:supmatch} (manifested in
different ways) and the idea of \ac{SCL} has close ties to \ac{DG} \citep{arjovsky2019invariant},
the focus of Chapter~\ref{ch:okapi}; in light of this, I afford dedicated discussion of the
\ac{SCL} problem and what conditions are needed to engender that problem.

%
After introducing, in turn, \ac{AF}, \ac{DA} and \ac{DA} -- as different realisations of the
\ac{DRO} problem --  term, I attempt to unify their problem setting distribution shift by drawing
upon causal principles.
%
To reiterate, while this thesis does not directly tangle with questions of causal inference, the field of
causality \citep{pearl2009causality} provides, through \acp{CBN} and interventions thereof, the
means of expressing different distribution shifts and the desired/undesired variances/invariances
using a single, formalised calculus.
%
Equipped with this calculus, I conclude this section -- as alluded to above -- with a rundown of
specific learning paradigms -- departing from the problem setups they can might be applied to --
featured throughout the works in this thesis, namely \ac{SemiSL}, \ac{AdvL}, and \acp{INN}.
%
