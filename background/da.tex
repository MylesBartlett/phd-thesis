% ********************************************************************************
\section{Domain adaptation}\label{sec:domain-adaptation}
% ********************************************************************************
\Acf{DA} contends with the problem of adapting a model trained on one distribution (the
\emph{source domain}) to a different but related distribution (the \emph{target domain}), in such a
way that the relevant shared structure is exploited while nuisance factors that are domain-specific
(and not relevant to the prediction task) ignored.
%
The downstream performance of the model is thus naturally dependent on both the performance on the
source domain and by the degree of relatedness between the source and target domains.
%
To proffer a real-world example, in building a spam detector, one might have annotated data
(emails) available for training a model sourced from a previous group of users and wish to deploy
(adapt) the detector to a new group of users in such a way that is robust to the temporal
distribution shift.

%
In the classical \ac{DA} setting, one assumes the distribution shift is \emph{covariate}
\citep{david2010impossibility} in nature, that is, localised to the marginal distribution \(P(X)\),
with both the conditional, \(P(Y|X)\) (corresponding to changes in the ground-truth labelling
mechanism, \( f^\star: \gX \to \gY \)), and label, \(P(Y)\), distributions consistent across
domains.
%
This is not to say that there is not a substantial body of work that addresses other types of
distribution shift \citep{zhao2019learning}, and the covariate-shift assumption is perhaps stricter
than one might initially presume.
%
Indeed, it turns out that the covariate-shift assumption is only tenable in cases where \(f^\star\)
is \emph{causal} (\(X \to Y\)); practically, there are many cases for which the converse in fact
holds true, i.e. the relationship between \(X\) and \(Y\) is \emph{anticausal} (\(Y \to X\)).
%
Anticausal prediction tasks naturally crop up in the medical-imaging domain for instance, where
\(Y\) is some gold-standard indicator of the presence of the disease and it is the disease that
gives rise to aberrations in the input images signalling to a classifier a positive instance. 
%
For the task of melanoma-prediction, for example, one may be interested in training a classifier to
diagnose patients based only on dermoscopic images using labels derived from (expensive and
time-consuming but reliable) histopathological analysis \citep{castro2020causality}.
%
The distinction between causal and anticausal tasks is an important one in \ac{ML} generally, and I
will revisit the idea on several occasions throughout the remainder of this chapter; for
\ac{SemiSL}, said distinction is particularly important as the efficacy of the paradigm hinges on
\( P(X) \) carrying information about \(f^\ast\), and thus the task being an anticausal one.
%
% \subsection{Taxonomy of methods} 
%
% See \cite{zhang2013domain} for an early example (and theoretically-rigorous presentation of)
% domain adaptation under (target and conditional) distribution shift.
