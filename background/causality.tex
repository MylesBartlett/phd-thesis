% ********************************************************************************
\section{Through the lens of causality}\label{sec:lens-of-causality}
% ********************************************************************************
I now introduce a causal formalism of the distribution-shift problem, a formalism which has been
frequently exploited in the \ac{DG} and \ac{AF} literature as it provides a simple calculus with
which to reason about desired (and undesired) variances.
%
It should be again noted that I only draw upon this formalism in order to provide a unified
formulation of the distribution-shift problems considered in this thesis; we do not operate on the
domain of causal graphs nor attempt to perform causal inference in any of the constituent works. 
%
The background on causality is thus commensurably light and I would refer the reader to
\citet{pearl2009causality} for full exposition of the topic.

While the term `domain' typically refers to the observed distributions as a whole in both \ac{DA}
and \ac{DG} alike (i.e. `source' versus 'target'), such terminology is somewhat rigid, as it fails
to capture that the distributions share an underlying structure and how and which variables are
shifted.
%
\marginpar{\textbf{Domain as an exogenous variable}}
%
It is arguably more flexible then, consistent with \citep{mooij2020joint}, to think of the domain
as some exogenous latent variable, which, by its conditioning, gives rise to the different observed
distributions -- or subgraphs in the discrete case -- and explains how one is transformed
(`shifted') into the other.
%
I will denote said variable as \(E\) (for `\textbf{E}nvironment', as it is commonly termed in the
\ac{DG} literature \citep{arjovsky2019invariant}), which need satisfy only the loose requirement that it
belong to some Borel space (and thus may in theory be continuous or discrete).
%
Most simply, in the case of \ac{DA}, \(E\) is simply a binary random variable, such that we have \(E:
\Omega \to \{ \text{source}, \text{target} \}\), with \( \Omega \) being the sample space.
%

We view then view variables in our prediction task as constituting the nodes \( \gV \) in a
\acl{CBN} (\acs{CBN}; \citealp{pearl1995bayesian}) where the direction of arrows (directed edges)
between nodes indicate the direction of causality (e.g. \(\rmA \to \rmB \) means that \textbf{A}
causes (is a parent of) \textbf{B}) while the absence of an edge between two nodes \textbf{A} and
\textbf{B} indicates independence between them when conditioned on their parents, i.e. \( \rmA |
\text{Pa}(\rmA) \perp \rmB | \text{Pa}(\rmB) \), where \( \text{Pa}(\cdot) \) denotes the causal
parents of its argument node.
%
Formally, a \ac{CBN} is a kind of \ac{DAG}, \(\rmG \triangleq \langle \gV, \xi
\rangle \) with node-set (variables), \(\gV\), and (directed) edge-set, \(\xi\) consisting of
tuples \((ij)\) meaning \(i \to j \), or `node \(i\) is a parent of node \(j\)'.
%
Each node in \( \rmG \) then defines a probability distribution, conditional on its parents, such
that the joint distribution of \(\gV\), \( P(V) \), factorises as \( P(V) = \prod_{v \in \gV} P(v |
\text{Pa}(v)) \) where we can now define \(\text{Pa}(\cdot)\) as a function that returns all nodes
in \(\xi\) that form a pair with \(v\) as the second element, i.e. \( \{ i | i,j \in \xi, j = v \}
\).
%

Without loss of generality, for the prediction task with inputs, \(X\), and targets, \(Y\), we may
introduce the aforementioned variable \(E\) to convert the joint distribution \(P(X, Y)\) into the
conditional joint distribution \( P(X, Y | E ) \); the structure of the underlying \ac{CBN} determines
the factorisation of this distribution and thus the nature of the distribution shift in question.
%
One can, for example characterise the case of covariate shift with causal \(f^\star\), as having
edges  \(E \to X\) and \( X \to Y \), giving rise to the factorisation \( P(X, Y | E) | P(E) =
P(Y|X)P(X|E)P(E) \). 
%
In Chapters~\ref{ch:nifr} and \ref{ch:supmatch}, we go beyond the bivariate (excepting \( E \)) and
covariate case and consider label-shift problems with an additional auxiliary label \(S\) --
corresponding to an identifier of some subgroup or spurious feature we wish to be invariant to in
the name of fairness or generalisation --  in which \(E\) influences the joint distribution \( P(S,
Y) \) but not the marginal distribution \(P(X)\), giving rise to representation bias and, from it,
\acp{SC}.
%
To reify this, I illustrate in Fig.~\ref{fig:ds_cbns} illustrate minimal \acp{CBN} corresponding to
different distribution shifts for a (causal) prediction task.
%
\import{background}{ds_cbns.tex}
%
% We will see that such a formulation is particularly useful when discussing \acl{DG} in
% \S\ref{sec:dg}, defining a problem setup involving a multitude of source distributions and thus
% going beyond the dyadic source-target setup characterising \ac{DA}.
%

% A popular \citep{arjovsky2019invariant, krueger2021out, sagawa2019distributionally} way of
% formulating the robust-prediction problem is as one of bilevel, or minimax, optimisation, where the
% inner loop entails computing the risk over each domain and the outer loop corresponds to finding
% the function that minimises the maximum of said risks.
I presented in \S\ref{ssec:minimax-fairness}, within the context of minmax fairness, a formulation
of the bilevel \ac{DRO} objective mathematises the desire to minimise the worst risk, where `worst`
is computed over a collection of sub-distributions, corresponding in said case of minimax fairness
to different sensitive attributes.
%
It is common to couch \ac{DG} in the same terms \citep{arjovsky2019invariant, krueger2021out,
sagawa2019distributionally}; with some restatement of that objective, using the new calculus, one
can define the optimal predictor over the (empirical) environment distribution \(\gE\) from
\ref{sec:dg} as
%
\begin{equation}\label{eq:rob-erm-obj} 
    f^\ast_\text{ robust } =
    %
    \underset{ f \in \gF }{ \mathrm{inf} }\, 
    % % %
    \underset{ e \in \gE}{ \mathrm{sup} }\,
    % %
    \E_{ P^{tr}( X, Y | E = e ) } [ \gL ( f( X ), Y ) ]. 
    %
\end{equation}
%
Given that domains/environments can be modelled as deriving from different interventions of the
causal factorisation of \(P(X, Y\)), it follows that, for Eq.~\ref{eq:rob-erm-obj} to engender
successful generalisation to arbitrary domains, \(\gE^\dagger\) outside \(\gE\) (\( \gE^\dagger
\cap \gE = \varnothing \); i.e. the goal of \ac{DG}), \(\gE\) must be a representative
(well-covering) set of samples from the generating distribution, \( P(E) \), such that smooth
interpolation along the underlying manifold is possible.
%
% When \(\gE\) is a finite set, as above, one can think of it as \emph{perturbation set}, accordant
% with the robust optimisation literature \citep{ben2009robust}.
%
To recall, though generalisation to arbitrary perturbations may be provably hard (or impossible;
\citealp{david2010impossibility}), when \(\gE\) encodes prior information about the kinds of
perturbations one expects to encounter at test-time then incorporating it into the optimisation
process can be fruitful, both for allowing interpolation within the convex hull defined by \(\gE\)
and to an extrapolated region outside of it \citep{krueger2021out}.
%
Indeed, one expects that by allowing the model to glean which features are and are not stable
across environments would allow it to better approximate the true causal structure of the
prediction task;
%
this idea has been explored extensively in recent years in both the causal discovery
\citep{peters2016causal, bengio2019meta} and \ac{DG} \citep{arjovsky2019invariant,
ahuja2020invariant, creager2021environment} literature (as discussed in \S\ref{sec:dg}), with the
caveat that a degree of inductive bias or additional information is necessary to provably identify
the correct causal relations \citep{lin2022zin}.
%

% % ------------------------------------------------------------------------------
% Points to incorporate from, and inspired from, \cite{scholkopf2021toward}:
% %
% /\begin{itemize} \item The Independent Causal Mechanisms (ICM) principle states, in short, that the
%     generative process giving rise to a system's observed variables is governed by
%     \emph{autonomous} modules that do not inform (have zero mutual information \wrt{}) or influence
%     each other.
%     %
%     In the probabilistic case, this means that the conditional distribution of each variable, given
%     its causes (parents), does not inform or influence other mechanisms.
%     %
%     Applied to casual factorisation, the principle dictates that the factors should be independent
%     in the sense that 
%     %
%     \begin{enumerate} \item Changing (intervening on) one mechanism in the system (CBN), \(P(i,
%         \text{Pa}(i))\) does not change any of the other mechanisms in the same system, \(P(j,
%         \text{Pa}(j))\), \(\forall j \neq i \).
%       %
% \item Knowing information about \(P(i, \text{Pa}(i))\) does not confer us additional knowledge
% about \(P(j, \text{Pa}(j))\), i.e. \( \forall (i \neq j): \gI(i; j) = 0 \). \end{enumerate}
%     %
% The notion of invariant, autonomous, and independent mechanisms has appeared in many guises
% throughout the history of causality research.
%     %
% The \emph{invariance criterion} of Herb Simon states that the true causal order is the one that is
% invariant under the right sort of intervention.
%     %
% Pearl avers that a causal mechanism remains invariant when other mechanisms are subjected to
% external (exogenous influence).
%     %
% One may then derive from the tenets of the ICM principle, the Sparse Mechanism Shift (SMS)
% hypothesis, which simply postulates that small distribution shifts tend to manifest themselves in a
% sparse of local way in a causal factorisation (i.e. not all factors should be affected
% simultaneously).
%     %
% A factorisation, on the other hand, that does not exhibit this behaviour can be said to be
% \emph{entangled}.

% \item According to the ICM principle, independence of two mechanisms should mean  that the two
%     conditional distributions do not inform or influence one another.
%     %
%     Note that this does not necessarily align with the notion of statistical dependency. \item
%     Causal structure captures the physical mechanisms that generate statistical dependencies in the
%     first place.
%     %
%     Statistical structure is an epiphenomenon that follows if we make unexplained variables random.
%     %
%     By virtue of modularity, a world model based on causally factorised latents is maximally
%     compressive in general, and by this we mean it provides the simplest explanation to the complex
%     physical world. 
%     %
%     It is much more efficient, for example, to explain changes in the shape of an object as one
%     moves around it by a change in vantage point, in terms of global symmetry, rather than by
%     independent changes in local structure, as would be explained by an \emph{entangled} model.
%     %
%     The connection between causal representation learning and modern physics thus becomes clear
%     when one thinks as modularity being synonymous with invariances, or \emph{symmetries}, with it
%     being little exaggeration to say that modern physics is the study of \emph{symmetries} and the
%     corresponding conserved quantities, as predicated by Noether's celebrated theorem
%     \citep{noether1918invariante}.
%     %
%     In light of this, the statistically- and causally-driven approaches are manifestly at odds with
%     one another in the context of shortcut learning -- shortcut features provide the simplest,
%     loss-minimising solution based on the training distribution, \(P^{tr}(X, Y)\), however they do
%     not provide the simplest solution in the causal sense as evidenced by the lack of
%     generalisability.
%     %
%     Models that are faithful to the underlying causal structure of the problem are much more robust
%     to distributional changes and are more protean because the learned modules can be reconfigured
%     arbitrarily according to the problem at hand and can be updated locally to incorporate new
%     information without degrading modules adapted for other, unrelated tasks.
%     %
% \item

% \end{itemize}

