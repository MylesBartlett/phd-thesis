% \section{Breaking Ill-Posedness with Stability Assumptions}

% We consider here the possibility of solving the seemingly ill-posed problem of one-to-one
% correspondence between the target attribute, $y$, and the spurious attribute $s$. While
% statistically decoupling the two is indeed impossible, we can leverage the fact that what makes $s$
% is spurious is that it offers a lower-complexity pathway, $p(y|s)$, relative to the true causal
% mechanism. More plainly, $s$ can be said to be spurious because it provides a simple shortcut in
% the training data for the loss minimizer; we can take advantage of the fact that simplicity
% connotes instability: low-level statistics such as illumination and texture, that are to blame of
% many of the elucidated spurious-correlation problems, are unstable \wrt{} transformations (
% augmentations) in the input domain. Texture information, for instance, can be erased (to a degree
% determined by the chosen bandwidth) by convolving the input image with a Gaussian (blur) kernel,
% while high-level properties such as shape and whole-part relations are largely preserved. Thus,
% augmentations provide the means of obviating many common spurious correlations; however, the problem is
% knowing which augmentations to apply a priori, or how to construct transformations operating on
% more abstract concepts -- in the case of our CelebA experiments where the target is confounded by
% \emph{gender}, one would be hard-pressed to design by hand a transformation that acts selectively
% on said confounder.

% \subsection{Learning General Invariances with Cooperative-Adversarial Augmentations} Inspired by
% meta-learning, we propose to simulate the spurious correlation problem using a set of of learned
% augmenters, $\mathcal{A}$. Each augmenter, $\a: \gX \times \gY \to \gX$, receives as input the
% original input $x$ as well as a conditioning factor $\silde{s} \in \gY$. Training is conducted over
% \emph{tasks}, $\tau \sim \gT$, by means of alternating \emph{train} and \emph{test} sessions, that
% we denote with $\frak{t}_tr$ and $\frak{t}_te$, respectively. 
% %
% The data for these sessions are constructed only batches drawn from the training data, and are
% distinguished only by how $\tilde{s}$ is sampled and in the sign of the augmenters' loss.
% Specifically, during train sessions, we set $\tilde{s} \triangleq y$ while during test sessions
% $\tilde{s}$ is uniformly sampled from $\gY: \tilde \gU(\gY)$, where $\gU$ denotes the (discrete)
% uniform distribution over its argument. Augmenters are then trained to \emph{minimise} the
% predictors loss (\emph{cooperative phase}) during training and to \emph{maximise) the loss during
%   test (\emph{adversarial phase}). The expressiveness and locality of the augmentations can be
%   controlled by changing the function class, $\gA$, from which $a$ is selected: when $\gA$
%   corresponds to the (infinite) set of parameterisations of a shallow convolutional network with a
%   small kernel size, for instance, then $a$ can only effect local transformations of the input. One
%   can imagine how this ability to inject prior knowledge about the form of the desired invariances
%   through the architecture of the augmenters might be a useful trait..
