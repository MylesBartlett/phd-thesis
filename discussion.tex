% -------------------------------------------------------------------------------
\chapter{Discussion}\label{ch:discussion}
% -------------------------------------------------------------------------------
\epigraph{
    %
    \emph{
        %
        ``I do not care what comes after; I have seen the dragons on the wind of morning.''
        %
} 
%
}
{The Farthest Shore\\Ursula K. Le Guin}
%
% \section*{Preamble}
% %
% And so we come to story's end, but the end of every story begets the beginning of a new one, or
% maybe the continuation of same one, and so the story may never truly end, but only perpetually
% change.
% %
% % Through the varied isles of ML we have sailed;
% Behind every story there is another story of how that story came to be, and together a greater
% story they may make;
% %
% for I might tell of the seeking of wisdom, from those sages that came before and those that
% in far-off realms now dwell, ever weaving, layer upon layer, their spells of computation to make
% magic of machine;
% %
% of bearding twin serpents, Byas and Koraleishen and seeing them reconciled with unlabelled aid;
% %
% and of parleying with the Wardens of the great Sancta of Knowledge -- Aykl\'ir, Ays\^iml, Esesevi,
% N\"ur\`ipsa, and time-honoured S\'iv\={i}piar, not least of all-- to earn entrance to their
% hallowed halls.

\section*{Of what was said and the silence between}\label{sec:what-was-said}
%
I have introduced three methods, each a solution to a different problem, though with all problems
conjoined by a notion of distributional robustness.
%
\sidepar{Synopsis}
%
To briefly recount, and thereby set the scene for the discussion to follow: in
Chapter~\ref{ch:nifr} we proposed an \ac{INN}-based transfer-learning approach -- transferring
invariance from a partially-labelled representative set to the training set -- for solving a
\ac{SC} problem where for training samples the target is completely determined by the
sensitive attribute and because the latter is easier to learn it constitutes a shortcut;
%
in Chapter~\ref{ch:supmatch}, we proposed to match in representation-space the support (of
intersectional groups) of the training and deployment sets in order to overcome a relaxed version
of aforesaid \ac{SC} problem where the deployment set is a dataset representative (in support) of
the test set, but for which no annotations are required, in contrast to the representative set
featured in Chapter~\ref{ch:nifr};
%
finally, in Chapter~\ref{ch:okapi} we grappled with the problem of semi-supervised \ac{DG} -- by
which I mean the problem of how to make effective use of unlabelled data drawn from extra domains
to bolster \ac{OOD} performance -- and proposed a consistency-regularised approach employing a
robust, causally-inspired algorithm as a match-generation engine, with the matches bootstrapped
from encodings guided (in optimisation) by past matches.
%
Again, all of these works are mine but not unshared, for I owe much gratitude to all my
co{\"a}uthors -- my colleagues, my advisors, my friends -- for allowing this thesis to become what
it has thus become.
%
\sidepar{The gift of hindsight}
%
I shall begin by discussing, with the gift of hindsight and the wisdom which comes with being
humbled by experience, the limitations of the works presented, and I will do so candidly: for as I
said at the outset, I do not fear the `lesser elements' -- for every candle lit there is a shadow
cast, but it is also because of the shadow that we may see the light.
%
Among these limitations, I shall begin with the most fundamental one that pervades all the works
and is itself bipartite, comprising the assumed availability of subgroup (I, arbitrarily, use this
term to cover the myriad names for \(S\) here) annotations, and the assumed discrete property of
these annotations.

%
In journeying through this thesis, we have witnessed a progressive relaxation of the first part,
such that in Chapter~\ref{ch:supmatch} we need only know in advance all possible (\wrt{} the test
set) sources (and know that the deployment set contains them); by Chapter~\ref{ch:okapi} we need
only be able to partition the data into two disjoint sets, across which the matching is performed.
%
We argued in Chapter~\ref{ch:nifr} that partially-labelled data, for which the subgroup- but not
the target-attribute is provided, is generally more `readily available'. 
%
While this may be true for certain domains and applications, it is not true for others, and it is
largely contingent on what the target and subgroup attributes have been determined to be, and,
moreover, how they interact (their relative complexity).
%
It is reasonable in the case of a face dataset like CelebA to assume that gender information can be
explicitly, or implicitly, gleaned -- for instance, by virtue of the images appearing in
gender-specific catalogues -- whereas `Smiling' is not a feature to innately partition by (and we
would assume that in the forgoing catalogue case that most models will be smiling), and these two
attributes would indeed realistically serve well as the subgroup and target attributes,
respectively, for Chapter~\ref{ch:nifr}'s framework; it is less easy to intuit whether a shortcut
would emerge though we contend there is no harm in taking the precaution if using a lossless
encoder.
%
If it were `Hair Colour' that we sought invariance to and `Age' we were targeting (this combination
plausible enough), however, we would not expect things to pan out nearly so neatly.

%
The problem of learning distributional-robust models from biased data, and circumventing \acp{SC}
thereof, when the distributions (subgroups) in question are unknown has attracted considerable
attention as of late (\cite{HasSriNamLia18, SohDunAngGuetal20, creager2021environment, liu2021just,
pezeshki2021gradient, taghanaki2022masktune, kim2022learning}, inter alia).
%
However, one must unavoidably rely on certain assumptions (inductive biases derived from prior
knowledge of the task/domain) to compensate for the lack of information and the referenced methods
can fall flat (in the sense of underperforming the ERM baseline) should such not be satisfiable.
%
Chapter~\ref{ch:supmatch} entails this to a degree, in that the sources contained in the deployment
set need be discovered for constructing support-representative batches, although the (annotated)
sources in the training set can subserve this process of discovery, for it is not entire subgroups
or classes that are excluded from annotation but their intersections.
%
Nonetheless, this discovery can fail to align with expectation, and we assume in
Chapter~\ref{ch:supmatch} that the subgroups/targets are sufficiently salient to be well-clustered
by un-/semi-supervised means -- one would not expect a source formed from gender/pulmonary
infiltration (subgroup and target attributes, respectively) to lend itself to natural clusters.

Speaking of the discreteness assumption, we have throughout assumed that the subgroup can be
represented, innately or by simple preprocessing, by some index; while this accords with much of
the literature (because of its simplicity and prevalence) there are nonetheless cases where this
assumption is untenable.
%
This is particularly germane to the method proposed in Chapter~\ref{ch:supmatch} which expects the
data to both be clusterable and for the sources to be finite (and, practically, small enough to be
computationally tractable) sets, such that one can balance batches \wrt{} them -- how one might
extend the method to continuous subgroups is unclear -- the notion perhaps not even sensible -- and
in order to maintain tractability in pursuit of generality it would seem necessary to cede some, or
all, of the theoretical guarantees established.
%
The adversarial-infomin approach adopted in Chapter~\ref{ch:nifr}, on the other hand, can be
readily adapted to continuous subgroups, for instance, by substituting cross-entropy with
\ac{HGRMC} (recalling that we use \ac{HGRMC} in said chapter not as an objective but as a fairness
metric for tasks involving \emph{categorical} subgroups).

%
I have spoken before of the practical deficiencies of the \ac{AdvL} paradigm in a \ac{DL} context
-- namely the fragility of optimisation, disposition to cyclic dynamics, architectural dependency,
and the loss of guarantees incurred by estimating the best-response dynamics with a finite
(typically small) number of steps -- but it is apposite that we revisit these points again here,
retrospectively instead of prospectively.
%
\sidepar{The idiosyncrasies of adversarial infomin}
%
Indeed -- as again spoken of before but of which there is again no harm recalling -- said
deficiencies have been well noted in the infomin-related literature, motivating attempts to develop
non-adversarial approaches, taking advantage of, for instance, the exact-density-estimation
afforded by \acp{NF} \citep{balunovic2021fair}, sliced mutual information
\citep{goldfeld2021sliced} to scalably target the infomin objective directly
\citep{chen2022scalable}, or the information-bottleneck principle \citep{tishby2015deep,
moyer2018invariant} for which the subgroup attribute plays the part of the \emph{nuisance factor},
to reconcile the parlance.
%
While cognisant of, and taking measures (e.g.\ ensembling, limiting the volume of the latent space)
to ameliorate, these deficiencies, the making of the aforesaid chapters was, in no small amount,
harried by them, often demanding careful and exhaustive tuning to coax the respective methods into
working as desired, the `tuning' itself problematic due to the underspecified nature of the problem
setups.
%
We found the inherent instability of \ac{AdvL} particularly pronounced in the case of
Chapter~\ref{ch:nifr}, specifically, owing to the compounding instabilities imparted by the
invertible architectures, a problem which itself would not be addressed \emph{in toto} until
\cite{behrmann2021understanding}.
%
In light of the forgoing, exploring non-adversarial methods, of the kind referenced, as alternative
infomin engines for the higher-level methods proposed in said chapters is well-founded (for those
wishing to apply, or undertake further research, on said methods), though I cannot -- despite their
theoretical appeal -- attest to their practical efficacy in these contexts, \emph{a priori}; I
would note in defence of the chapters, however, that for neither higher-level method is the form of
said engine integral to its identity, and is in fact modular, such that we may conceivably freely
interchange engines subject to their respective requirements.
%
In Chapter~\ref{ch:okapi} we induce invariance by non-adversarial means ourselves, namely by
enforcing similarity between matched samples from different domains within representation space --
the adversary substituted with a non-parametric match-generator -- and we thereby avert many of the
optimisation difficulties plaguing the aforementioned chapters, though the problem of judicious
hyperparameter-selection lingers, perhaps even amplified by the non-parametricity -- we point in
the paper to adaptive-configuration of the calipers being an obvious (in motivation but not
implementation) avenue of extension.
%

\sidepar{On the problem of identifiability}
%
A central question that I have perhaps given shorter shrift to than due, is that of the
identifiability of bias -- a question of two parts: 1) diagnosing those cases warranting
methodological (or data-sided) interventions, such as those delineated; 2) and evaluating the
success of those interventions -- given the element of underspecification
\citep{semenova2019study}.
%
The obtuse answer would be that it need not be answered, or answerable, presupposing that the model
in question (figuratively) is to be deployed regardless with or without intervention (the control),
for comparisons should be made \wrt{} the latter rather than \wrt{} an ideal, a gold-standard that
may (and often will not be) practically realisable -- one need only ensure that performance does
not degrade based on what is evaluable.
%
%
This cavalier ethos of `do the best we can with what's available [short of bringing humans directly
into the fold], regardless of the consequences', however is patently not an admirable one, however,
and realistically one (a practitioner or collective) does, or should, aim to deploy models subject
to their being sensible/unbiased (if only for reputation's sake) and to thoroughly diagnose, and
attempt to remedy failure cases via well-measured and iterative processes.
%
The problem of underspecification -- of validating models without access to data representative of
that to-be-encountered at deployment time, as defines \ac{DG} -- that encapsulates the second
aspect of the question remains an outstanding one, that has been discussed broadly and in the
context of \ac{DG} specifically, posing a threat to the validity of inter-method comparisons
\citep{gulrajani2020search}.
%
\sidepar{Interpretability and oversight}
%
In absence of a such validation set by which to quantify biases and generalisation-failures, one
may draw upon methods from the explainability/interpretability literature \citep{gunning2019xai} to
determine whether the learned solutions align with the intended solutions; one may, for instance,
readily diagnose the use of background as a shortcut, per the now-canonical example from
\citet{beery2018recognition}, with a standard-method-in-that-literature in Grad-cam
\citep{selvaraju2017grad}, allowing for a targeted intervention (e.g.\ by augmentation) -- one may
even use the resulting attribution maps directly for this purpose as proposed by
\citet{taghanaki2022masktune}.
%
It is for this reason that we emphasise the interpretability aspect in Chapter~\ref{ch:nifr}, for
even if we cannot sufficiently debias a model (if it need be debiased), we might glean when this is
the case and for what reason without need for quantification.
%
This is, of course, easier for some domains than others -- images being naturally interpretable due
to their underlying structure and familiarity (the window through which we, quite literally, see
the world), whereas tabular data generally affords no such luxuries -- but the bottom line of this
excursis is my advocacy (which I am certainly not unique for) for human oversight, and the rigorous
model-vetting it should beget, irrespective of the theoretical trustability of the methods/data.
 
%
\sidepar{Theoretical-groundedness}
%
As far as limitations go, I shall last speak expressly of empirical and theoretical claims, and the
desire to couple the two.
%
In Chapter~\ref{ch:supmatch} we provide theoretical guarantees regarding when the proposed
support-matching should succeed, subject to certain (relatively-loose) assumptions about the
data-generating distributions.
%
Chapter~\ref{ch:okapi}, however, features no such proofs -- only intuition -- for the efficacy of
its respective method, that being a notable weakness of the current incarnation of the paper --
having such may serve to guide us regarding the configuration of the matching algorithm and thereby
obviate the somewhat-lengthy hyperparameter-selection procedure went through to obtain the
presented results.
%
In Chapter~\ref{ch:nifr}, on the other hand, we leverage an established infomin framework, around
which (or in the vicinity of which) there is a significant body of existing theoretical work --
both within the context of the various subfields \ac{ML} concerned with it (\ac{DA}, \ac{DG},
\ac{AF}) and within the broader context of game theory, dynamical systems theory, and information
theory -- however, we again furnish only intuition and empirical claims for the stabilisation
techniques, for which (proof-driven) theoretical-grounding would be demonstrably desirable.

%
\section*{Of what has since become and might yet be}\label{sec:what-might-yet-be}
%
\sidepar{Learning from human preferences and scaling supervision}
%
Recent work on AI-alignment has proposed `scaling supervision' (understanding `supervision' to mean
what I called before `oversight') of generative-language models by using human-aligned LLMs not
only as the model-to be-supervised, but also as the supervisor, acting according to a set of values
(in the form of prompts), or `constitution', specified by the practitioner
\citep{bowman2022measuring, bai2022constitutional}.
%
Such AI supervisors exhibit the ability to accurately, and well-calibratedly, detect biases
violating said constitution in generated responses and provide feedback for redressing them; this
feedback may be used to further align the supervised model, as substitute for the human-generated
feedback fuelling the eponymous \acl{RLHF} (\acs{RLHF}; \citealp{christiano2017deep,
    stiennon2020learning, bai2022training}), analogously termed \acf{RLAIF}.
%
While \ac{RLHF} does not allow for sidestepping of annotations (which has been ameliorated by
unprecedented levels of crowdsourcing), tuning based on preferences (given for pairs of responses)
allows for increased expressivity compared with traditional supervised approaches, pertinent when
the bias exists on a (difficult-to-quantify) spectrum or is fundamentally subjective in nature.
% (different individuals or entire cultures have different conceptions may what is considered
% `offensive', for example).
%
RLXF (to coin a catch-all initialism for reinforcement learning from some kind of feedback) affords
a spectacularly simple and general paradigm in terms of alignment and distributional robustness
(that we view throughout this thesis in terms of invariance and worst-group performance) yet it and
fairness should not be confused as one and the same though despite their frequent overlap -- for
some tasks there is no subjective element to engender the notion of `preference', i.e.\ the value
system is fixed (inherently or by legislation), and so may be the answer-set (e.g.\ the label-set
for closed-set classification). 
%
Thus, while one may use RLXF to obtain generative models that are more helpful/harmless/honest (the
`HHH triad') -- a sense of `debiasing' -- it is no panacea for problems of the nature discussed in
this thesis, especially so for specialised tasks for which there is little prior knowledge --
acquired from large-scale pre-training -- to be leveraged; methods like those presented herein
might then still have their place in this brave new world of ML where multi-modal foundation models
\citep{driess2023palm, huang2023language, openai2023gpt4, katz2023gpt} and RLXF putatively rule the
roost (though most definitely the headlines).
%
The premise of scaling supervision, through this process of self-review, as in
\citet{bai2022constitutional}, may have broader application, however: for image-classification, one
could conceive of a model that classifies based on natural-language descriptions of a scene,
providing a reasoning mechanism that is evaluable by `constitutional' critics and human auditors
(who, again, should very much remain part of the equation -- they are to be assisted not
superseded).
%

%
Beyond this alignment-centric perspective, it is also appropriate to speak of the merits of
large-scale pre-training, and subsequent fine-tuning, from a non-generative perspective and rather
in terms of the distributionally-robustness representations it may give rise to; whereas the focus
before was on the language domain, here it will be on the vision one which preponderated in this
thesis's works, due foremost to its interpretability.
%
A host of prominent works attest that large-scale (primarily self-supervised) training improves
downstream robustness for visual tasks, in both covariate \citep{hendrycks2019using,
hendrycks2020pretrained, radford2021learning} and target/subgroup senses \citep{liu2021self,
goyal2022vision}, with \citet{goyal2022vision} showing that the pre-training corpus, if of
sufficient scale (here being on the order of millions of samples), need not be curated for this to
apply -- curation being the natural enemy of scalability, which begets diversity which itself
subserves robustness, at least in the \ac{OOD} sense (for it cannot  necessarily imply invariance
in general).
%
Thus, for some \ac{OOD}/\ac{DG} tasks, one may not need to resort to dedicated algorithms, but
instead simply fine-tune, or use as is, the representations of such foundation models -- one may
even be able to obviate the need to perform any manner of fine-tuning if the task in question is
sufficiently general as to admit zero-shot solutions by vision-language models
\citep{radford2021learning, alayrac2022flamingo}.
%
There are two issues that prevent or hinder such foundation-model-based approaches from providing
general-purpose solutions, however. 
%
The first I have alluded to before, that being that for tasks of a specialised nature -- such as
those found in medical imaging -- we would expect the degree of positive transfer from large-scale
web-derived datasets to be limited, on the representation front, and zero-shot approaches all the
more inauspicious; the second is that the robustness of pre-training models is known to degrade
(become `distorted') as the result of fine-tuning processes \citep{andreassen2021evolution,
kumar2022finetuning}, a phenomenon which can be mitigated but not altogether averted, at present --
the development of more-robust, less-distorting fine-tuning routines remains an active area of
research \citep{lee2022surgical, trivedi2023closer}.
%
An additional concern, of a more practical, but not innegligibly-niche nature, is that running the
germane foundation model might demand more compute or time than can be afforded, even when run in
inference mode (simply loading larger foundation models into memory can be challenging, requiring
model-sharding), this being most-obviously applicable to low-compute edge devices.
%
These issues aside, while foundation models may pave some of the way to robustness, in certain
respects, it will often be the case that one can do better given the data available, and the
remainder of the way need be paved with dedicated distributionally-robust methods; in cases where
no annotations for the attribute to-be-invariant to are given or obtainable, however, they do
provide a promising recourse, one that requires few, if no, assumptions -- one may obtain
robustness for `free', so to speak -- and little to no (in the zero-shot case) compute be spent on
training, albeit with the aforementioned caveat on compute standing.
%
